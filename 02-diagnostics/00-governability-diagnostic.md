# Governability Diagnostic

Purpose:
This is a structured instrument for evaluating whether a system, workflow, AI, or organization is controllable, auditable, and safe to scale.

This diagnostic does not ask:
"Does it work?"

It asks:
"Can we govern it when it fails?"

---

## Section 1 — Ownership

- Who owns this system?
- Who can stop it?
- Who is accountable when it causes harm?
- Who approves changes?

---

## Section 2 — Control

- Can this system be paused?
- Can it be rolled back?
- Can it be sandboxed?
- Can it be rate-limited?

---

## Section 3 — Visibility

- Can we see what it is doing?
- Can we explain its decisions?
- Can we audit its outputs?
- Can we detect drift or misuse?

---

## Section 4 — Failure Modes

- What happens when it fails?
- What happens when dependencies fail?
- What happens when operators fail?
- What happens when incentives break?

---

## Section 5 — Irreversibility

- What actions cannot be undone?
- What data cannot be recalled?
- What decisions permanently change state?
- Who approved those risks?

---

## Section 6 — Scale Risk

- What changes when this is 10x larger?
- What breaks at 100x?
- What becomes uncontrollable at 1000x?

---

## Final Judgment

- Is this system governable? (Yes / No / Unknown)
- What must be true before this is allowed to scale?
